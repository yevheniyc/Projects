<!DOCTYPE html>
<html lang="en">
<head>
 <title>Building the next-generation big data analytics stack - O'Reilly Media</title>
</head>
<body>
<div id="article-body">
<p>I first tried Spark around the version 0.4 and 0.5 releases. At the time, I was using <a href="https://hive.apache.org/">Hive</a> and <a href="https://pig.apache.org/">Pig</a> for data processing, while evaluating <a href="https://mahout.apache.org/">Mahout</a> for machine learning. Other than being a bit resistant to having to learn a new programming language -- Scala -- which I later came to love, I immediately became a user and fan of Spark. The speed gains were addicting! AMPLab was also starting to roll out useful examples and libraries at a steady pace, and I soon found myself finding reasons to use Spark on more tasks and projects.</p>
<p>Interacting with and getting feedback from developers at local meetups was important to the students and Professors of AMPLab. Around mid 2012, there was <a href="http://www.meetup.com/spark-users/events/69193112/">a San Francisco meetup</a> where the audience got to see a preview of Spark Streaming. I remember the reaction to the presentation very clearly. There was immediate interest and enthusiasm, and it was clear to me that Spark Streaming was going to be popular. At the time, many in the audience used <a href="http://storm.apache.org/">Storm</a>, and the prospect of a simplified infrastructure (due to Spark's ability to handle both batch and streaming) was attractive to many in attendance. It was at this meetup that I first broached the idea of a Spark book to <a href="https://en.wikipedia.org/wiki/Matei_Zaharia">Matei Zaharia</a> (the creator of Spark). That initial conversation led to the popular O'Reilly title, <a href="https://www.safaribooksonline.com/library/view/learning-spark/9781449359034/?utm_source=oreilly&amp;utm_medium=newsite&amp;utm_campaign=michael-franklin-data-show-post-text-link">Learning Spark</a>.</p>
<p>In the fall of 2012, I was fortunate enough to get invited to <a href="http://ampcamp.berkeley.edu/amp-camp-one-berkeley-2012/">the first AMP Camp</a>, and while I was enroute to that event, I wrote my first post on Spark (<a href="https://www.oreilly.com/ideas/seven-reasons-why-i-like-spark">Seven reasons why I like Spark</a>). AMP Camps combined talks as well as hands-on tutorials and in the early days of Spark they became the defacto community gathering for users. A few things stood out for me in that first AMP Camp. First, the tutorials were cloud-friendly from the beginning: AMP Camp tutorials provided tools to help users play with Spark on <a href="https://aws.amazon.com/">AWS</a>. Second, the unveiling of <a href="http://spark.apache.org/docs/latest/api/python/">Pyspark</a> came at a time when most of the early users had JVM (Java, Scala, Clojure) backgrounds. This opened up Spark to the large number of data scientists who use Python as their primary language. This has worked out extremely well -- the most recent user survey suggests Python and Scala have the same number of users in the Spark community. Finally, machine learning was featured prominently at that first AMP Camp. From the early days of Spark, many users, including myself, were drawn to its potential for machine learning tasks.</p>
</div>

<div class="text-group">
<p>
 By
           <a href="/people/4e7ad-ben-lorica">
            Ben Lorica
           </a>
</p>
    <p class="copyright">
      2016 O'Reilly Media, Inc. All trademarks and registered trademarks appearing on oreilly.com are the property of their respective owners.
    </p>
</div>
</body>
</html>

